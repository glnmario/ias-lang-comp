{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6882390b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T20:31:32.526498Z",
     "start_time": "2024-04-10T20:31:24.999030Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import KFold \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5761b",
   "metadata": {},
   "source": [
    "### Load the preprocessed Aligned corpus (includes surprisal and incremental information value estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7cd42b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T20:33:31.679612Z",
     "start_time": "2024-04-10T20:31:32.523757Z"
    }
   },
   "outputs": [],
   "source": [
    "aligned_norm = pd.read_csv(\"preprocessed_corpora/aligned_preprocessed_normalised.csv\")\n",
    "\n",
    "# aligned.columns = aligned.columns.str.replace(\"-\", \"_\")\n",
    "aligned_norm.columns = aligned_norm.columns.str.replace(\"-\", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9d3fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T20:33:31.681370Z",
     "start_time": "2024-04-10T20:33:31.678026Z"
    }
   },
   "outputs": [],
   "source": [
    "# For interaction terms\n",
    "\n",
    "def all_pairs(list):\n",
    "    \"\"\"\n",
    "    Returns all possible pairs of elements in a list\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for i in range(len(list)):\n",
    "        for j in range(i+1, len(list)):\n",
    "            pairs.append([list[i], list[j]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59172e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T20:33:31.683493Z",
     "start_time": "2024-04-10T20:33:31.678809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DISTANCE_METRICS = [\"cosine_std\"]  #[\"euclidean\", \"cosine\", \"euclidean_std\", \"cosine_std\"]\n",
    "MODEL_NAMES = ['gpt2_small', 'gpt2_medium', 'gpt2_large', 'gpt2_xl']\n",
    "HORIZONS = range(1, 11)\n",
    "LAYERS = {\n",
    "    \"gpt2_small\": list(range(0, 13)),\n",
    "    \"gpt2_medium\": list(range(0, 25, 2)),\n",
    "    \"gpt2_large\": list(range(0, 37, 3)),\n",
    "    \"gpt2_xl\": list(range(0, 49, 4))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "RATINGS = ['rating_mean','rating_sd', 'cloze_p_smoothed', 'cloze_s', 'entropy']\n",
    "ERP = ['ELAN', 'LAN', 'N400', 'EPNP', 'P600', 'PNP']\n",
    "RT = ['RTfirstfix', 'RTfirstpass', 'RTrightbound', 'RTgopast', 'self_paced_reading_time']\n",
    "ALL_PREDICTED_VARIABLES = RATINGS + RT + ERP\n",
    "\n",
    "BASELINE_PREDICTORS = ['Subtlex_log10', 'context_length', 'length']\n",
    "SURPRISAL_PREDICTORS = [col for col in aligned_norm if '_surprisal' in col]\n",
    "IAS_PREDICTORS = [col for col in aligned_norm if '_ias_' in col]\n",
    "ALL_INFORMATION_PREDICTORS = SURPRISAL_PREDICTORS + IAS_PREDICTORS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb3c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take the log of all IAS predictors\n",
    "# for col in IAS_PREDICTORS:\n",
    "#     aligned_norm[col] = np.log(aligned_norm[col] + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61fdf63",
   "metadata": {},
   "source": [
    "### Horizon-layer combinations\n",
    "\n",
    "#### Surprisal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b4e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5803b519010441f2a2e89f93173e37c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m predictors \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m IAS_PREDICTORS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_H\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhorizon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_L\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_D\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdist_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_S\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mstartswith(model) \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(predictors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m OLS_model \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mols\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpredicted_var\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m ~ \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbaseline_predictors_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m + \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_surprisal + \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpredictors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_tmp\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     39\u001b[0m anova_results \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39manova_lm(OLS_baseline, OLS_model)\n\u001b[1;32m     41\u001b[0m results_horizon_layer_combinations\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: predicted_var, \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mias_coef\u001b[39m\u001b[38;5;124m\"\u001b[39m: OLS_model\u001b[38;5;241m.\u001b[39mparams[predictors[\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m     67\u001b[0m })\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:203\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 203\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_formula_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m    206\u001b[0m max_endog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_formula_max_endog\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/formula/formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_util\u001b[38;5;241m.\u001b[39m_is_using_pandas(Y, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 63\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         result \u001b[38;5;241m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m                            NA_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_iter_maker\u001b[39m():\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([data])\n\u001b[0;32m--> 164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_try_incr_builders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_design_matrices(design_infos, data,\n\u001b[1;32m    168\u001b[0m                                  NA_action\u001b[38;5;241m=\u001b[39mNA_action,\n\u001b[1;32m    169\u001b[0m                                  return_type\u001b[38;5;241m=\u001b[39mreturn_type)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/highlevel.py:66\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdesign_matrix_builders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs_termlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs_termlist\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/build.py:719\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    717\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m termlist \u001b[38;5;129;01min\u001b[39;00m termlists:\n\u001b[0;32m--> 719\u001b[0m     term_to_subterm_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_make_subterm_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtermlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnum_column_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mcat_levels_contrasts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(term_to_subterm_infos, OrderedDict)\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(term_to_subterm_infos) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(termlist)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/build.py:604\u001b[0m, in \u001b[0;36m_make_subterm_infos\u001b[0;34m(terms, num_column_counts, cat_levels_contrasts)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m bucket_terms:\n\u001b[1;32m    603\u001b[0m     subterm_infos \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 604\u001b[0m     factor_codings \u001b[38;5;241m=\u001b[39m \u001b[43mpick_contrasts_for_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mnum_column_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mused_subterms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Construct one SubtermInfo for each subterm\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor_coding \u001b[38;5;129;01min\u001b[39;00m factor_codings:\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/redundancy.py:227\u001b[0m, in \u001b[0;36mpick_contrasts_for_term\u001b[0;34m(term, numeric_factors, used_subterms)\u001b[0m\n\u001b[1;32m    225\u001b[0m subterms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subset \u001b[38;5;129;01min\u001b[39;00m _subsets_sorted(categorical_factors):\n\u001b[0;32m--> 227\u001b[0m     subterm \u001b[38;5;241m=\u001b[39m \u001b[43m_Subterm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_ExpandedFactor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subterm \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m used_subterms:\n\u001b[1;32m    229\u001b[0m         subterms\u001b[38;5;241m.\u001b[39mappend(subterm)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/patsy/redundancy.py:80\u001b[0m, in \u001b[0;36m_Subterm.__init__\u001b[0;34m(self, efactors)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_Subterm\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlso immutable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, efactors):\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mefactors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(efactors)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcan_absorb\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# returns True if 'self' is like a-:b-, and 'other' is like a-\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_horizon_layer_combinations = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model including surprisal\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models by horizon-layer combination\n",
    "        for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            for horizon in range(1, 11):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    \n",
    "                    assert(len(predictors) == 1)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {predictors[0]}',\n",
    "                        data=df_tmp\n",
    "                    ).fit()\n",
    "\n",
    "                    anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                    results_horizon_layer_combinations.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": layer,\n",
    "                        \"layer_idx\": layer_idx,\n",
    "                        \"horizon\": horizon,\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": \"full\", \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": anova_results.ssr[1],\n",
    "                        \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                        \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                        \"ftest_p\": \"\",\n",
    "                        \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                        \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                    })\n",
    "        \n",
    "\n",
    "        # # ---------------------------------------------------\n",
    "        # # 10-fold bootstrapping for IAS models\n",
    "        # # ---------------------------------------------------\n",
    "        # kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        # kf.get_n_splits(df_tmp) \n",
    "\n",
    "        # for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "        #     df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "        #     # first fit baseline model including surprisal\n",
    "        #     OLS_baseline = smf.ols(\n",
    "        #         formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "        #         data=df_tmp_fold\n",
    "        #     ).fit()     \n",
    "\n",
    "        #     # fit IAS models by horizon-layer combination\n",
    "        #     for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "        #         for horizon in range(1, 11):\n",
    "        #             for dist_metric in DISTANCE_METRICS:\n",
    "        #                 predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "\n",
    "        #                 assert(len(predictors) == 1)\n",
    "\n",
    "        #                 OLS_model = smf.ols(\n",
    "        #                     formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {predictors[0]}',\n",
    "        #                     data=df_tmp_fold\n",
    "        #                 ).fit()\n",
    "\n",
    "        #                 anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "        #                 results_horizon_layer_combinations.append({\n",
    "        #                     \"y\": predicted_var, \n",
    "        #                     \"metric\": \"Information value\", \n",
    "        #                     \"model\": model, \n",
    "        #                     \"layer\": layer,\n",
    "        #                     \"layer_idx\": layer_idx,\n",
    "        #                     \"horizon\": horizon,\n",
    "        #                     \"aggregation\": \"mean\",\n",
    "        #                     \"dist_metric\": dist_metric,\n",
    "        #                     \"fold\": fold, \n",
    "        #                     \"loglik\": OLS_model.llf,\n",
    "        #                     \"rsquared\": OLS_model.rsquared,\n",
    "        #                     \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "        #                     \"aic\": OLS_model.aic,\n",
    "        #                     \"bic\": OLS_model.bic,\n",
    "        #                     \"delta_loglik\": OLS_model.llf - OLS_baseline.llf,\n",
    "        #                     \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "        #                     \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "        #                     \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "        #                     \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "        #                     \"anova_rss\": anova_results.ssr[1],\n",
    "        #                     \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "        #                     \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "        #                     \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "        #                     \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "        #                 })\n",
    "\n",
    "       \n",
    "results_horizon_layer_combinations_df = pd.DataFrame(results_horizon_layer_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1466.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS_model.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f4b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_horizon_layer_combinations_df.to_csv(\n",
    "    \"results/ols_aligned_ias_cosine_std_horizon_layer_over_surprisal.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640b109",
   "metadata": {},
   "source": [
    "#### Against control baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fd90f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1996b376f24fd5b537767cdbd7fc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_horizon_layer_combinations = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model including control predictors\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models by horizon-layer combination\n",
    "        for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            for horizon in range(1, 11):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "\n",
    "                    assert(len(predictors) == 1)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {predictors[0]}',\n",
    "                        data=df_tmp\n",
    "                    ).fit()\n",
    "\n",
    "                    anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                    results_horizon_layer_combinations.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": layer,\n",
    "                        \"layer_idx\": layer_idx,\n",
    "                        \"horizon\": horizon,\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": \"full\", \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": anova_results.ssr[1],\n",
    "                        \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                        \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                        \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                    })\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp)\n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including control predictors\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "            # fit IAS models by horizon-layer combination\n",
    "            for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "                for horizon in range(1, 11):\n",
    "                    for dist_metric in DISTANCE_METRICS:\n",
    "                        predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "\n",
    "                        assert(len(predictors) == 1)\n",
    "\n",
    "                        OLS_model = smf.ols(\n",
    "                            formula=f'{predicted_var} ~ {baseline_predictors_str} + {predictors[0]}',\n",
    "                            data=df_tmp_fold\n",
    "                        ).fit()\n",
    "\n",
    "                        anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                        results_horizon_layer_combinations.append({\n",
    "                            \"y\": predicted_var, \n",
    "                            \"metric\": \"Information value\", \n",
    "                            \"model\": model, \n",
    "                            \"layer\": layer,\n",
    "                            \"layer_idx\": layer_idx,\n",
    "                            \"horizon\": horizon,\n",
    "                            \"aggregation\": \"mean\",\n",
    "                            \"dist_metric\": dist_metric,\n",
    "                            \"fold\": fold, \n",
    "                            \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                            \"rsquared\": OLS_model.rsquared,\n",
    "                            \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                            \"aic\": OLS_model.aic,\n",
    "                            \"bic\": OLS_model.bic,\n",
    "                            \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                            \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                            \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                            \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                            \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                            \"anova_rss\": anova_results.ssr[1],\n",
    "                            \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                            \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                            \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                        })\n",
    "       \n",
    "results_horizon_layer_combinations_df = pd.DataFrame(results_horizon_layer_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9ad4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_horizon_layer_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_horizon_layer_against_control.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08197ee0",
   "metadata": {},
   "source": [
    "#### Head-to-head comparison with surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "393b3c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7290bea7972b46f9a628a46415fe02ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 0.36146465368110464\n",
      "anova nan\n",
      "f 0.35546565825046655\n",
      "anova nan\n",
      "f 0.37585152275572864\n",
      "anova nan\n",
      "f 0.364289308547202\n",
      "anova nan\n",
      "f 0.355672290754783\n",
      "anova nan\n",
      "f 0.349000039883552\n",
      "anova nan\n",
      "f 0.34296388892394297\n",
      "anova nan\n",
      "f 0.3360554269085063\n",
      "anova nan\n",
      "f 0.3298644989352419\n",
      "anova nan\n",
      "f 0.32636824571083334\n",
      "anova nan\n",
      "f 0.36454927872301324\n",
      "anova nan\n",
      "f 0.3448341677023346\n",
      "anova nan\n",
      "f 0.3496124023734903\n",
      "anova nan\n",
      "f 0.34036427612445824\n",
      "anova nan\n",
      "f 0.3301198271433326\n",
      "anova nan\n",
      "f 0.32191691576511944\n",
      "anova nan\n",
      "f 0.318100196616814\n",
      "anova nan\n",
      "f 0.314149239207099\n",
      "anova nan\n",
      "f 0.3100009448035633\n",
      "anova nan\n",
      "f 0.30789976293033033\n",
      "anova nan\n",
      "f 0.34637103120290114\n",
      "anova nan\n",
      "f 0.32895294915173023\n",
      "anova nan\n",
      "f 0.3464947862359848\n",
      "anova nan\n",
      "f 0.33959119801267157\n",
      "anova nan\n",
      "f 0.3312546075360631\n",
      "anova nan\n",
      "f 0.32578109437782093\n",
      "anova nan\n",
      "f 0.3223141513395691\n",
      "anova nan\n",
      "f 0.3185160175585196\n",
      "anova nan\n",
      "f 0.3145666013398269\n",
      "anova nan\n",
      "f 0.31217064810773404\n",
      "anova nan\n",
      "f 0.3352148769357823\n",
      "anova nan\n",
      "f 0.3191269399160349\n",
      "anova nan\n",
      "f 0.3344413242584837\n",
      "anova nan\n",
      "f 0.3228241245324572\n",
      "anova nan\n",
      "f 0.3120061309537122\n",
      "anova nan\n",
      "f 0.3058605329537692\n",
      "anova nan\n",
      "f 0.30182886462751995\n",
      "anova nan\n",
      "f 0.2980800530307703\n",
      "anova nan\n",
      "f 0.29484129139458587\n",
      "anova nan\n",
      "f 0.2932412458066354\n",
      "anova nan\n",
      "f 0.3276064302691623\n",
      "anova nan\n",
      "f 0.3166175070415936\n",
      "anova nan\n",
      "f 0.3262901482442151\n",
      "anova nan\n",
      "f 0.3125987303749475\n",
      "anova nan\n",
      "f 0.3018387526069585\n",
      "anova nan\n",
      "f 0.2960898248728155\n",
      "anova nan\n",
      "f 0.29237298754945396\n",
      "anova nan\n",
      "f 0.28919139483961753\n",
      "anova nan\n",
      "f 0.2869463840065574\n",
      "anova nan\n",
      "f 0.2861066460669199\n",
      "anova nan\n",
      "f 0.31824468221842633\n",
      "anova nan\n",
      "f 0.3198345066573527\n",
      "anova nan\n",
      "f 0.3285715156459219\n",
      "anova nan\n",
      "f 0.3124130046420481\n",
      "anova nan\n",
      "f 0.30037760125984303\n",
      "anova nan\n",
      "f 0.29358722301497137\n",
      "anova nan\n",
      "f 0.2891553081672537\n",
      "anova nan\n",
      "f 0.2856810236666402\n",
      "anova nan\n",
      "f 0.2834438062540001\n",
      "anova nan\n",
      "f 0.2823795179491766\n",
      "anova nan\n",
      "f 0.310251643298597\n",
      "anova nan\n",
      "f 0.3242078446755488\n",
      "anova nan\n",
      "f 0.3275137419163722\n",
      "anova nan\n",
      "f 0.3105887826359288\n",
      "anova nan\n",
      "f 0.2994806536676318\n",
      "anova nan\n",
      "f 0.29317230879147094\n",
      "anova nan\n",
      "f 0.28908477603326593\n",
      "anova nan\n",
      "f 0.2856575953254468\n",
      "anova nan\n",
      "f 0.2835205767784034\n",
      "anova nan\n",
      "f 0.2824246050798609\n",
      "anova nan\n",
      "f 0.3018406794737203\n",
      "anova nan\n",
      "f 0.32227580552446766\n",
      "anova nan\n",
      "f 0.32398527149193496\n",
      "anova nan\n",
      "f 0.3078990411797988\n",
      "anova nan\n",
      "f 0.2975956777970925\n",
      "anova nan\n",
      "f 0.2914131589432844\n",
      "anova nan\n",
      "f 0.2873259632511113\n",
      "anova nan\n",
      "f 0.28399406031076174\n",
      "anova nan\n",
      "f 0.28181697836148234\n",
      "anova nan\n",
      "f 0.2806195806656143\n",
      "anova nan\n",
      "f 0.2923022101015497\n",
      "anova nan\n",
      "f 0.31940847961301244\n",
      "anova nan\n",
      "f 0.3177576143447741\n",
      "anova nan\n",
      "f 0.30292843442869466\n",
      "anova nan\n",
      "f 0.2936489026594999\n",
      "anova nan\n",
      "f 0.2878437373330582\n",
      "anova nan\n",
      "f 0.2841348204844651\n",
      "anova nan\n",
      "f 0.28108195036630046\n",
      "anova nan\n",
      "f 0.2791553260645945\n",
      "anova nan\n",
      "f 0.278161942479106\n",
      "anova nan\n",
      "f 0.28293795537176547\n",
      "anova nan\n",
      "f 0.31332385083538816\n",
      "anova nan\n",
      "f 0.3077208431302572\n",
      "anova nan\n",
      "f 0.29483623026450884\n",
      "anova nan\n",
      "f 0.28745738045531066\n",
      "anova nan\n",
      "f 0.2828283793809242\n",
      "anova nan\n",
      "f 0.2797219138670186\n",
      "anova nan\n",
      "f 0.2771262882306063\n",
      "anova nan\n",
      "f 0.27558172704171957\n",
      "anova nan\n",
      "f 0.2749598525332193\n",
      "anova nan\n",
      "f 0.2757893536875895\n",
      "anova nan\n",
      "f 0.3064276424326366\n",
      "anova nan\n",
      "f 0.3000582785865337\n",
      "anova nan\n",
      "f 0.29004235601104295\n",
      "anova nan\n",
      "f 0.2845605446729559\n",
      "anova nan\n",
      "f 0.28101008672400474\n",
      "anova nan\n",
      "f 0.27871131367213114\n",
      "anova nan\n",
      "f 0.2767150073499342\n",
      "anova nan\n",
      "f 0.27574393308202677\n",
      "anova nan\n",
      "f 0.2755712861554759\n",
      "anova nan\n",
      "f 0.26988558502607685\n",
      "anova nan\n",
      "f 0.3002502619620603\n",
      "anova nan\n",
      "f 0.2927507212043338\n",
      "anova nan\n",
      "f 0.28445353334078294\n",
      "anova nan\n",
      "f 0.2801842146936265\n",
      "anova nan\n",
      "f 0.2774015614743139\n",
      "anova nan\n",
      "f 0.27583260370582224\n",
      "anova nan\n",
      "f 0.27426279671158277\n",
      "anova nan\n",
      "f 0.2735896114546445\n",
      "anova nan\n",
      "f 0.27366607874631815\n",
      "anova nan\n",
      "f 0.2904814891530524\n",
      "anova nan\n",
      "f 0.3195994760510341\n",
      "anova nan\n",
      "f 0.31143955641609583\n",
      "anova nan\n",
      "f 0.29866365612956125\n",
      "anova nan\n",
      "f 0.29221387932802856\n",
      "anova nan\n",
      "f 0.2876405213214879\n",
      "anova nan\n",
      "f 0.28460659418828443\n",
      "anova nan\n",
      "f 0.28180544758585685\n",
      "anova nan\n",
      "f 0.2799587955305058\n",
      "anova nan\n",
      "f 0.2789938129096831\n",
      "anova nan\n",
      "f 0.3863031427967001\n",
      "anova nan\n",
      "f 0.3570144485728821\n",
      "anova nan\n",
      "f 0.371781397991582\n",
      "anova nan\n",
      "f 0.360983150096953\n",
      "anova nan\n",
      "f 0.35473909749357607\n",
      "anova nan\n",
      "f 0.348491860163577\n",
      "anova nan\n",
      "f 0.3406465396683747\n",
      "anova nan\n",
      "f 0.33272105725678963\n",
      "anova nan\n",
      "f 0.32668662654641967\n",
      "anova nan\n",
      "f 0.3208317127174091\n",
      "anova nan\n",
      "f 0.3626929355365184\n",
      "anova nan\n",
      "f 0.31830303623744544\n",
      "anova nan\n",
      "f 0.3298920695805504\n",
      "anova nan\n",
      "f 0.3229216252570069\n",
      "anova nan\n",
      "f 0.3178205221053991\n",
      "anova nan\n",
      "f 0.3135727246391451\n",
      "anova nan\n",
      "f 0.3100817601871319\n",
      "anova nan\n",
      "f 0.3059699589013673\n",
      "anova nan\n",
      "f 0.30344187817140555\n",
      "anova nan\n",
      "f 0.3013094451571312\n",
      "anova nan\n",
      "f 0.3346114669295305\n",
      "anova nan\n",
      "f 0.3193727148384931\n",
      "anova nan\n",
      "f 0.34525082792189454\n",
      "anova nan\n",
      "f 0.3398078714688283\n",
      "anova nan\n",
      "f 0.33397381647078095\n",
      "anova nan\n",
      "f 0.32934526763794475\n",
      "anova nan\n",
      "f 0.325216180831239\n",
      "anova nan\n",
      "f 0.3208387004949631\n",
      "anova nan\n",
      "f 0.3174112546904573\n",
      "anova nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(predictors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m OLS_model \u001b[38;5;241m=\u001b[39m smf\u001b[38;5;241m.\u001b[39mols(\n\u001b[1;32m     35\u001b[0m     formula\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_predictors_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     data\u001b[38;5;241m=\u001b[39mdf_tmp\n\u001b[1;32m     37\u001b[0m )\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 39\u001b[0m anova_results \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manova_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOLS_baseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOLS_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m f \u001b[38;5;241m=\u001b[39m anova_results\u001b[38;5;241m.\u001b[39mssr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m anova_results\u001b[38;5;241m.\u001b[39mssr[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     42\u001b[0m df0 \u001b[38;5;241m=\u001b[39m OLS_baseline\u001b[38;5;241m.\u001b[39mdf_model\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/stats/anova.py:367\u001b[0m, in \u001b[0;36manova_lm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m table \u001b[38;5;241m=\u001b[39m DataFrame(np\u001b[38;5;241m.\u001b[39mzeros((n_models, \u001b[38;5;241m6\u001b[39m)), columns\u001b[38;5;241m=\u001b[39mnames)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scale: \u001b[38;5;66;03m# assume biggest model is last\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\n\u001b[1;32m    369\u001b[0m table[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [mdl\u001b[38;5;241m.\u001b[39mssr \u001b[38;5;28;01mfor\u001b[39;00m mdl \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    370\u001b[0m table[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_resid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [mdl\u001b[38;5;241m.\u001b[39mdf_resid \u001b[38;5;28;01mfor\u001b[39;00m mdl \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/base/wrapper.py:34\u001b[0m, in \u001b[0;36mResultsWrapper.__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     36\u001b[0m how \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_attrs\u001b[38;5;241m.\u001b[39mget(attr)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/tools/decorators.py:95\u001b[0m, in \u001b[0;36mCachedAttribute.__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     93\u001b[0m _cachedval \u001b[38;5;241m=\u001b[39m _cache\u001b[38;5;241m.\u001b[39mget(name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cachedval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     _cachedval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     _cache[name] \u001b[38;5;241m=\u001b[39m _cachedval\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cachedval\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1717\u001b[0m, in \u001b[0;36mRegressionResults.scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;129m@cache_writable\u001b[39m()\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscale\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m    A scale factor for the covariance matrix.\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \n\u001b[1;32m   1714\u001b[0m \u001b[38;5;124;03m    The Default value is ssr/(n-p).  Note that the square root of `scale`\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;124;03m    is often called the standard error of the regression.\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m     wresid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwresid\u001b[49m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(wresid, wresid) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_resid\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1699\u001b[0m, in \u001b[0;36mRegressionResults.wresid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwresid\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03m    The residuals of the transformed/whitened regressand and regressor(s).\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mwendog \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/mario/code/ias-lang-comp/.venv/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:412\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[0;34m(self, params, exog)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_horizon_layer_combinations = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model including surprisal\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models by horizon-layer combination\n",
    "        for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            for horizon in range(1, 11):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    \n",
    "                    assert(len(predictors) == 1)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {predictors[0]}',\n",
    "                        data=df_tmp\n",
    "                    ).fit()\n",
    "\n",
    "                    anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                    f = anova_results.ssr[0] / anova_results.ssr[1]\n",
    "                    df0 = OLS_baseline.df_model\n",
    "                    df1 = OLS_model.df_model\n",
    "                    p_value = stats.f.cdf(f, df0, df1)\n",
    "\n",
    "                    print('f', p_value)\n",
    "                    print('anova', anova_results['Pr(>F)'][1])\n",
    "                    \n",
    "\n",
    "                    results_horizon_layer_combinations.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": layer,\n",
    "                        \"layer_idx\": layer_idx,\n",
    "                        \"horizon\": horizon,\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": \"full\", \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": anova_results.ssr[1],\n",
    "                        \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                        \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                        \"surprisal_coef\": OLS_baseline.params[f\"{model}_surprisal\"],\n",
    "                        \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                    })\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # # 10-fold bootstrapping for IAS models\n",
    "        # # ---------------------------------------------------\n",
    "\n",
    "        # kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        # kf.get_n_splits(df_tmp)\n",
    "\n",
    "        # for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "        #     df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "        #     # first fit baseline model including surprisal\n",
    "        #     OLS_baseline = smf.ols(\n",
    "        #         formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "        #         data=df_tmp_fold\n",
    "        #     ).fit()     \n",
    "\n",
    "            # # fit IAS models by horizon-layer combination\n",
    "            # for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            #     for horizon in range(1, 11):\n",
    "            #         for dist_metric in DISTANCE_METRICS:\n",
    "            #             predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "\n",
    "            #             assert(len(predictors) == 1)\n",
    "\n",
    "            #             OLS_model = smf.ols(\n",
    "            #                 formula=f'{predicted_var} ~ {baseline_predictors_str} + {predictors[0]}',\n",
    "            #                 data=df_tmp_fold\n",
    "            #             ).fit()\n",
    "\n",
    "            #             anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "            #             results_horizon_layer_combinations.append({\n",
    "            #                 \"y\": predicted_var, \n",
    "            #                 \"metric\": \"Information value\", \n",
    "            #                 \"model\": model, \n",
    "            #                 \"layer\": layer,\n",
    "            #                 \"layer_idx\": layer_idx,\n",
    "            #                 \"horizon\": horizon,\n",
    "            #                 \"aggregation\": \"mean\",\n",
    "            #                 \"dist_metric\": dist_metric,\n",
    "            #                 \"fold\": fold, \n",
    "            #                 \"loglik\": OLS_model.llf,\n",
    "            #                 \"rsquared\": OLS_model.rsquared,\n",
    "            #                 \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "            #                 \"aic\": OLS_model.aic,\n",
    "            #                 \"bic\": OLS_model.bic,\n",
    "            #                 \"delta_loglik\": OLS_model.llf - OLS_baseline.llf,\n",
    "            #                 \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "            #                 \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "            #                 \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "            #                 \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "            #                 \"anova_rss\": anova_results.ssr[1],\n",
    "            #                 \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "            #                 \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "            #                 \"surprisal_coef\": OLS_baseline.params[f\"{model}_surprisal\"],\n",
    "            #                 \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "            #             })\n",
    "\n",
    "results_horizon_layer_combinations_df = pd.DataFrame(results_horizon_layer_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b2adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_horizon_layer_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_horizon_layer_replace_surprisal.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91925aa3",
   "metadata": {},
   "source": [
    "### Layer-level predictors \n",
    "\n",
    "#### Against surprisal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4b2e048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea213e8cc5b4dea87a7f9ef1eddb202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_layer_combinations_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models layer-wise\n",
    "        for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "                assert(len(predictors) == 10)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                results_layer_combinations_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": layer,\n",
    "                    \"layer_idx\": layer_idx,\n",
    "                    \"horizon\": \"All\",\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": anova_results.ssr[1],\n",
    "                    \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                    \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "        \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "            for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    \n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    assert(len(predictors) == 10)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "                    \n",
    "                    results_layer_combinations_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": layer,\n",
    "                        \"layer_idx\": layer_idx,\n",
    "                        \"horizon\": \"All\",\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": \"\",\n",
    "                        \"anova_delta_ss\": \"\",\n",
    "                        \"anova_p\": \"\"\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "\n",
    "       \n",
    "results_layer_combinations_df = pd.DataFrame(results_layer_combinations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4646a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_layer_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_layer_against_surprisal.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ef00e",
   "metadata": {},
   "source": [
    "#### Against control baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "599884d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097386d63cad47528d52b1f7a812e90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_layer_combinations_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models layer-wise\n",
    "        for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "                assert(len(predictors) == 10)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str}  + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                results_layer_combinations_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": layer,\n",
    "                    \"layer_idx\": layer_idx,\n",
    "                    \"horizon\": \"All\",\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": anova_results.ssr[1],\n",
    "                    \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                    \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "        \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str}',\n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "            for layer_idx, layer in enumerate(LAYERS[model]):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    \n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_L{layer}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    assert(len(predictors) == 10)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "                    \n",
    "                    results_layer_combinations_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": layer,\n",
    "                        \"layer_idx\": layer_idx,\n",
    "                        \"horizon\": \"All\",\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": \"\",\n",
    "                        \"anova_delta_ss\": \"\",\n",
    "                        \"anova_p\": \"\"\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "\n",
    "       \n",
    "results_layer_combinations_df = pd.DataFrame(results_layer_combinations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69ad7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_layer_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_layer_against_control.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4bc265",
   "metadata": {},
   "source": [
    "### Horizon-level predictors\n",
    "\n",
    "#### Against surprisal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a93ff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d08c364e3c0498aba74a1760231beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_horizon_combinations_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models layer-wise\n",
    "        for horizon in range(1, 11):\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "                assert(len(predictors) == 13)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                results_horizon_combinations_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": \"All\",\n",
    "                    \"layer_idx\": \"All\",\n",
    "                    \"horizon\": horizon,\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": anova_results.ssr[1],\n",
    "                    \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                    \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "        \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "            for horizon in range(1, 11):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    \n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    assert(len(predictors) == 13)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "                    \n",
    "                    results_horizon_combinations_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": \"All\",\n",
    "                        \"layer_idx\": \"All\",\n",
    "                        \"horizon\": horizon,\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": \"\",\n",
    "                        \"anova_delta_ss\": \"\",\n",
    "                        \"anova_p\": \"\"\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "\n",
    "       \n",
    "results_horizon_combinations_df = pd.DataFrame(results_horizon_combinations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9399a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_horizon_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_horizon_against_surprisal.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7575fa8",
   "metadata": {},
   "source": [
    "#### Against control baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29fe0dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a914f7bc64434da230c04b8ade53c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_horizon_combinations_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models layer-wise\n",
    "        for horizon in range(1, 11):\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "                assert(len(predictors) == 13)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str}  + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "                results_horizon_combinations_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": \"All\",\n",
    "                    \"layer_idx\": \"All\",\n",
    "                    \"horizon\": horizon,\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": anova_results.ssr[1],\n",
    "                    \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                    \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "        \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str}',\n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "            for horizon in range(1, 11):\n",
    "                for dist_metric in DISTANCE_METRICS:\n",
    "                    \n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_H{horizon}_\" in p and f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                    assert(len(predictors) == 13)\n",
    "\n",
    "                    OLS_model = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "                    \n",
    "                    results_horizon_combinations_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": \"Information value\", \n",
    "                        \"model\": model, \n",
    "                        \"layer\": \"All\",\n",
    "                        \"layer_idx\": \"All\",\n",
    "                        \"horizon\": horizon,\n",
    "                        \"aggregation\": \"mean\",\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                        \"rsquared\": OLS_model.rsquared,\n",
    "                        \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                        \"aic\": OLS_model.aic,\n",
    "                        \"bic\": OLS_model.bic,\n",
    "                        \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                        \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                        \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                        \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                        \"anova_rss\": \"\",\n",
    "                        \"anova_delta_ss\": \"\",\n",
    "                        \"anova_p\": \"\"\n",
    "                    # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                    # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "\n",
    "       \n",
    "results_horizon_combinations_df = pd.DataFrame(results_horizon_combinations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f28848",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_horizon_combinations_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_horizon_against_control.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3982e",
   "metadata": {},
   "source": [
    "### Full model \n",
    "\n",
    "#### Against surprisal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "328f8bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a71c01f94b24382a2e8893ae75f0149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_full_model_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models \n",
    "        for dist_metric in DISTANCE_METRICS:\n",
    "            predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "            assert(len(predictors) == 130)\n",
    "\n",
    "            OLS_model = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                data=df_tmp\n",
    "            ).fit()\n",
    "\n",
    "            anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "            results_full_model_df.append({\n",
    "                \"y\": predicted_var, \n",
    "                \"metric\": \"Information value\", \n",
    "                \"model\": model, \n",
    "                \"layer\": \"All\",\n",
    "                \"layer_idx\": \"All\",\n",
    "                \"horizon\": \"All\",\n",
    "                \"aggregation\": \"mean\",\n",
    "                \"dist_metric\": dist_metric,\n",
    "                \"fold\": \"full\", \n",
    "                \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                \"rsquared\": OLS_model.rsquared,\n",
    "                \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                \"aic\": OLS_model.aic,\n",
    "                \"bic\": OLS_model.bic,\n",
    "                \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                \"anova_rss\": anova_results.ssr[1],\n",
    "                \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "            })\n",
    "    \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                \n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                assert(len(predictors) == 130)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp_fold\n",
    "                ).fit()\n",
    "                \n",
    "                results_full_model_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": \"All\",\n",
    "                    \"layer_idx\": \"All\",\n",
    "                    \"horizon\": \"All\",\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": fold, \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": \"\",\n",
    "                    \"anova_delta_ss\": \"\",\n",
    "                    \"anova_p\": \"\"\n",
    "                # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "            })\n",
    "\n",
    "       \n",
    "results_full_model_df = pd.DataFrame(results_full_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e0bfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full_model_df.to_csv(\n",
    "    \"results/ols_aligned_ias_cosine_std_full_model_against_surprisal.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e6cb5",
   "metadata": {},
   "source": [
    "#### Against control baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8818342f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0c550bee794def957615eb87cd49cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_full_model_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    for model in MODEL_NAMES:\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # ANOVA for IAS models\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        # first fit baseline model\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "            data=df_tmp\n",
    "        ).fit()        \n",
    "            \n",
    "        # fit IAS models \n",
    "        for dist_metric in DISTANCE_METRICS:\n",
    "            predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")] \n",
    "\n",
    "            assert(len(predictors) == 130)\n",
    "\n",
    "            OLS_model = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                data=df_tmp\n",
    "            ).fit()\n",
    "\n",
    "            anova_results = sm.stats.anova_lm(OLS_baseline, OLS_model)\n",
    "\n",
    "            results_full_model_df.append({\n",
    "                \"y\": predicted_var, \n",
    "                \"metric\": \"Information value\", \n",
    "                \"model\": model, \n",
    "                \"layer\": \"All\",\n",
    "                \"layer_idx\": \"All\",\n",
    "                \"horizon\": \"All\",\n",
    "                \"aggregation\": \"mean\",\n",
    "                \"dist_metric\": dist_metric,\n",
    "                \"fold\": \"full\", \n",
    "                \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                \"rsquared\": OLS_model.rsquared,\n",
    "                \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                \"aic\": OLS_model.aic,\n",
    "                \"bic\": OLS_model.bic,\n",
    "                \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                \"anova_rss\": anova_results.ssr[1],\n",
    "                \"anova_delta_ss\": anova_results.ss_diff[1],\n",
    "                \"anova_p\": anova_results['Pr(>F)'][1],\n",
    "                # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "            })\n",
    "    \n",
    "    \n",
    "        # ---------------------------------------------------\n",
    "        # 10-fold bootstrapping for IAS models\n",
    "        # ---------------------------------------------------\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        kf.get_n_splits(df_tmp) \n",
    "\n",
    "        for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "            df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "            # first fit baseline model including surprisal\n",
    "            OLS_baseline = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()     \n",
    "\n",
    "\n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                \n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(\"Smean\")]\n",
    "                assert(len(predictors) == 130)\n",
    "\n",
    "                OLS_model = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp_fold\n",
    "                ).fit()\n",
    "                \n",
    "                results_full_model_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": \"Information value\", \n",
    "                    \"model\": model, \n",
    "                    \"layer\": \"All\",\n",
    "                    \"layer_idx\": \"All\",\n",
    "                    \"horizon\": \"All\",\n",
    "                    \"aggregation\": \"mean\",\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": fold, \n",
    "                    \"loglik\": OLS_model.llf / OLS_model.nobs,\n",
    "                    \"rsquared\": OLS_model.rsquared,\n",
    "                    \"rsquared_adj\": OLS_model.rsquared_adj,\n",
    "                    \"aic\": OLS_model.aic,\n",
    "                    \"bic\": OLS_model.bic,\n",
    "                    \"delta_loglik\": OLS_model.llf / OLS_model.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"delta_rsquared\": OLS_model.rsquared - OLS_baseline.rsquared, \n",
    "                    \"delta_rsquared_adj\": OLS_model.rsquared_adj - OLS_baseline.rsquared_adj, \n",
    "                    \"delta_aic\": OLS_model.aic - OLS_baseline.aic,\n",
    "                    \"delta_bic\": OLS_model.bic - OLS_baseline.bic,\n",
    "                    \"anova_rss\": \"\",\n",
    "                    \"anova_delta_ss\": \"\",\n",
    "                    \"anova_p\": \"\"\n",
    "                # \"surprisal_coef\": OLS_model.params[f\"{model}_surprisal\"],\n",
    "                # \"ias_coef\": OLS_model.params[predictors[0]],\n",
    "                })\n",
    "\n",
    "       \n",
    "results_full_model_df = pd.DataFrame(results_full_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9a683c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full_model_df.to_csv(\n",
    "    \"results/ols_aligned_ias_cosine_std_full_model_against_control.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c035750",
   "metadata": {},
   "source": [
    "### Surprisal together with incremental information value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588bdca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e291f61fead4e4d9f987315cfc11686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038eaaa8f88a422baf583048a084b55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_variables = ALL_PREDICTED_VARIABLES\n",
    "all_predictors = ALL_INFORMATION_PREDICTORS\n",
    "\n",
    "baseline_predictors = BASELINE_PREDICTORS\n",
    "baseline_predictors_str = \" + \".join(baseline_predictors) + \" + \" + \" + \".join([f\"{p[0]}:{p[1]}\" for p in all_pairs(baseline_predictors)])\n",
    "    \n",
    "\n",
    "results_comparison_df = []\n",
    "\n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "    \n",
    "    # baseline model\n",
    "    OLS_baseline = smf.ols(\n",
    "        formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "        data=df_tmp\n",
    "    ).fit()\n",
    "\n",
    "    results_comparison_df.append({\n",
    "        \"y\": predicted_var, \n",
    "        \"metric\": \"Baseline\", \n",
    "        \"model\": \"\", \n",
    "        \"aggregation\": \"\",\n",
    "        \"dist_metric\": \"\",\n",
    "        \"fold\": \"full\", \n",
    "        \"loglik\": OLS_baseline.llf / OLS_baseline.nobs,\n",
    "        \"delta_loglik\": \"\",\n",
    "        \"rsquared\": OLS_baseline.rsquared,\n",
    "        \"delta_rsquared\": \"\",\n",
    "        \"rsquared_adj\": OLS_baseline.rsquared_adj,\n",
    "        \"delta_rsquared_adj\": \"\",\n",
    "        \"aic\": OLS_baseline.aic,\n",
    "        \"bic\": OLS_baseline.bic,\n",
    "        \"anova_p_vs_baseline\": \"\",\n",
    "        \"anova_p_ias_vs_surprisal\": \"\",\n",
    "        \"anova_p_surprisal_vs_ias\": \"\",\n",
    "    })\n",
    "    \n",
    "    for model in MODEL_NAMES:\n",
    "\n",
    "        OLS_surprisal = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "            data=df_tmp\n",
    "        ).fit()\n",
    "\n",
    "        anova_results_surprisal_vs_baseline = sm.stats.anova_lm(OLS_baseline, OLS_surprisal)\n",
    "\n",
    "        results_comparison_df.append({\n",
    "            \"y\": predicted_var, \n",
    "            \"metric\": \"Surprisal\", \n",
    "            \"model\": model, \n",
    "            \"aggregation\": \"\",\n",
    "            \"dist_metric\": \"\",\n",
    "            \"fold\": \"full\", \n",
    "            \"loglik\": OLS_surprisal.llf / OLS_surprisal.nobs,\n",
    "            \"delta_loglik\": OLS_surprisal.llf / OLS_surprisal.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "            \"rsquared\": OLS_surprisal.rsquared,\n",
    "            \"delta_rsquared\": OLS_surprisal.rsquared - OLS_baseline.rsquared,\n",
    "            \"rsquared_adj\": OLS_surprisal.rsquared_adj,\n",
    "            \"delta_rsquared_adj\": OLS_surprisal.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "            \"aic\": OLS_surprisal.aic,\n",
    "            \"bic\": OLS_surprisal.bic,\n",
    "            \"anova_p_vs_baseline\": anova_results_surprisal_vs_baseline['Pr(>F)'][1],\n",
    "            \"anova_p_ias_vs_surprisal\": \"\",\n",
    "            \"anova_p_surprisal_vs_ias\": \"\",\n",
    "            \"anova_p_both_vs_ias\": \"\",\n",
    "            \"anova_p_both_vs_surprisal\": \"\",\n",
    "        })\n",
    "            \n",
    "        # fit IAS models \n",
    "        for dist_metric in DISTANCE_METRICS:\n",
    "            for aggregation in [\"Smean\", \"Smin\"]:\n",
    "                predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(aggregation)]\n",
    "\n",
    "                assert(len(predictors) == 130)\n",
    "\n",
    "                OLS_ias = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results_ias_vs_baseline = sm.stats.anova_lm(OLS_baseline, OLS_ias)\n",
    "                anova_results_ias_vs_surprisal = sm.stats.anova_lm(OLS_surprisal, OLS_ias)\n",
    "                anova_results_surprisal_vs_ias = sm.stats.anova_lm(OLS_ias, OLS_surprisal)\n",
    "\n",
    "                results_comparison_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": f\"IAS ({aggregation[1:]})\",\n",
    "                    \"model\": model, \n",
    "                    \"aggregation\": aggregation,\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_ias.llf / OLS_ias.nobs,\n",
    "                    \"delta_loglik\": OLS_ias.llf / OLS_ias.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"rsquared\": OLS_ias.rsquared,\n",
    "                    \"delta_rsquared\": OLS_ias.rsquared - OLS_baseline.rsquared,\n",
    "                    \"rsquared_adj\": OLS_ias.rsquared_adj,\n",
    "                    \"delta_rsquared_adj\": OLS_ias.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "                    \"aic\": OLS_ias.aic,\n",
    "                    \"bic\": OLS_ias.bic,\n",
    "                    \"anova_p_vs_baseline\": anova_results_ias_vs_baseline['Pr(>F)'][1],\n",
    "                    \"anova_p_ias_vs_surprisal\": anova_results_ias_vs_surprisal['Pr(>F)'][1],\n",
    "                    \"anova_p_surprisal_vs_ias\": anova_results_surprisal_vs_ias['Pr(>F)'][1],\n",
    "                    \"anova_p_both_vs_ias\": \"\",\n",
    "                    \"anova_p_both_vs_surprisal\": \"\",\n",
    "                })\n",
    "\n",
    "                OLS_ias_surprisal = smf.ols(\n",
    "                    formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)} + {model}_surprisal',\n",
    "                    data=df_tmp\n",
    "                ).fit()\n",
    "\n",
    "                anova_results_both_vs_baseline = sm.stats.anova_lm(OLS_baseline, OLS_ias_surprisal)\n",
    "                anova_results_both_vs_ias = sm.stats.anova_lm(OLS_ias, OLS_ias_surprisal)\n",
    "                anova_results_both_vs_surprisal = sm.stats.anova_lm(OLS_surprisal, OLS_ias_surprisal)\n",
    "\n",
    "                results_comparison_df.append({\n",
    "                    \"y\": predicted_var, \n",
    "                    \"metric\": f\"Surprisal + IAS ({aggregation[1:]})\",\n",
    "                    \"model\": model, \n",
    "                    \"aggregation\": aggregation,\n",
    "                    \"dist_metric\": dist_metric,\n",
    "                    \"fold\": \"full\", \n",
    "                    \"loglik\": OLS_ias_surprisal.llf / OLS_ias_surprisal.nobs,\n",
    "                    \"delta_loglik\": OLS_ias_surprisal.llf / OLS_ias_surprisal.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                    \"rsquared\": OLS_ias_surprisal.rsquared,\n",
    "                    \"delta_rsquared\": OLS_ias_surprisal.rsquared - OLS_baseline.rsquared,\n",
    "                    \"rsquared_adj\": OLS_ias_surprisal.rsquared_adj,\n",
    "                    \"delta_rsquared_adj\": OLS_ias_surprisal.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "                    \"aic\": OLS_ias_surprisal.aic,\n",
    "                    \"bic\": OLS_ias_surprisal.bic,\n",
    "                    \"anova_p_vs_baseline\": anova_results_both_vs_baseline['Pr(>F)'][1],\n",
    "                    \"anova_p_ias_vs_surprisal\": \"\",\n",
    "                    \"anova_p_surprisal_vs_ias\": \"\",\n",
    "                    \"anova_p_both_vs_ias\": anova_results_both_vs_ias['Pr(>F)'][1],\n",
    "                    \"anova_p_both_vs_surprisal\": anova_results_both_vs_surprisal['Pr(>F)'][1],\n",
    "                })\n",
    "            \n",
    "    \n",
    "    \n",
    "for predicted_var in tqdm(predicted_variables):\n",
    "\n",
    "    df_tmp = aligned_norm[[predicted_var] + baseline_predictors + all_predictors].dropna()\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 10-fold bootstrapping \n",
    "    # ---------------------------------------------------\n",
    "    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    kf.get_n_splits(df_tmp) \n",
    "\n",
    "    for fold, (split_indices, _) in enumerate(kf.split(df_tmp)):\n",
    "        df_tmp_fold = df_tmp.iloc[split_indices]\n",
    "\n",
    "        # first fit baseline model including surprisal\n",
    "        OLS_baseline = smf.ols(\n",
    "            formula=f'{predicted_var} ~ {baseline_predictors_str}', \n",
    "            data=df_tmp_fold\n",
    "        ).fit()     \n",
    "\n",
    "        results_comparison_df.append({\n",
    "            \"y\": predicted_var, \n",
    "            \"metric\": \"Baseline\", \n",
    "            \"model\": \"\", \n",
    "            \"aggregation\": \"\",\n",
    "            \"dist_metric\": \"\",\n",
    "            \"fold\": fold, \n",
    "            \"loglik\": OLS_baseline.llf / OLS_baseline.nobs,\n",
    "            \"delta_loglik\": \"\",\n",
    "            \"rsquared\": OLS_baseline.rsquared,\n",
    "            \"delta_rsquared\": \"\",\n",
    "            \"rsquared_adj\": OLS_baseline.rsquared_adj,\n",
    "            \"delta_rsquared_adj\": \"\",\n",
    "            \"aic\": OLS_baseline.aic,\n",
    "            \"bic\": OLS_baseline.bic,\n",
    "            \"anova_p_vs_baseline\": \"\",\n",
    "            \"anova_p_ias_vs_surprisal\": \"\",\n",
    "            \"anova_p_surprisal_vs_ias\": \"\",\n",
    "        })\n",
    "\n",
    "        for model in MODEL_NAMES:\n",
    "\n",
    "            OLS_surprisal = smf.ols(\n",
    "                formula=f'{predicted_var} ~ {baseline_predictors_str} + {model}_surprisal', \n",
    "                data=df_tmp_fold\n",
    "            ).fit()\n",
    "\n",
    "            results_comparison_df.append({\n",
    "                \"y\": predicted_var, \n",
    "                \"metric\": \"Surprisal\", \n",
    "                \"model\": model, \n",
    "                \"aggregation\": \"\",\n",
    "                \"dist_metric\": \"\",\n",
    "                \"fold\": fold, \n",
    "                \"loglik\": OLS_surprisal.llf / OLS_surprisal.nobs,\n",
    "                \"delta_loglik\": OLS_surprisal.llf / OLS_surprisal.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                \"rsquared\": OLS_surprisal.rsquared,\n",
    "                \"delta_rsquared\": OLS_surprisal.rsquared - OLS_baseline.rsquared,\n",
    "                \"rsquared_adj\": OLS_surprisal.rsquared_adj,\n",
    "                \"delta_rsquared_adj\": OLS_surprisal.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "                \"aic\": OLS_surprisal.aic,\n",
    "                \"bic\": OLS_surprisal.bic,\n",
    "                \"anova_p_vs_baseline\": \"\",\n",
    "                \"anova_p_ias_vs_surprisal\": \"\",\n",
    "                \"anova_p_surprisal_vs_ias\": \"\",\n",
    "                \"anova_p_both_vs_ias\": \"\",\n",
    "                \"anova_p_both_vs_surprisal\": \"\",\n",
    "            })\n",
    "\n",
    "            # fit IAS models \n",
    "            for dist_metric in DISTANCE_METRICS:\n",
    "                for aggregation in [\"Smean\", \"Smin\"]:\n",
    "                    predictors = [p for p in IAS_PREDICTORS if f\"_D{dist_metric}_S\" in p and p.startswith(model) and p.endswith(aggregation)]\n",
    "\n",
    "                    assert(len(predictors) == 130)\n",
    "\n",
    "                    OLS_ias = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)}',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "\n",
    "                    results_comparison_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": f\"IAS ({aggregation[1:]})\", \n",
    "                        \"model\": model, \n",
    "                        \"aggregation\": aggregation,\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_ias.llf / OLS_ias.nobs,\n",
    "                        \"delta_loglik\": OLS_ias.llf / OLS_ias.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"rsquared\": OLS_ias.rsquared,\n",
    "                        \"delta_rsquared\": OLS_ias.rsquared - OLS_baseline.rsquared,\n",
    "                        \"rsquared_adj\": OLS_ias.rsquared_adj,\n",
    "                        \"delta_rsquared_adj\": OLS_ias.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "                        \"aic\": OLS_ias.aic,\n",
    "                        \"bic\": OLS_ias.bic,\n",
    "                        \"anova_p_vs_baseline\": \"\",\n",
    "                        \"anova_p_ias_vs_surprisal\": \"\",\n",
    "                        \"anova_p_surprisal_vs_ias\": \"\",\n",
    "                        \"anova_p_both_vs_ias\": \"\",\n",
    "                        \"anova_p_both_vs_surprisal\": \"\",\n",
    "                    })\n",
    "\n",
    "                    OLS_ias_surprisal = smf.ols(\n",
    "                        formula=f'{predicted_var} ~ {baseline_predictors_str} + {\"+\".join(predictors)} + {model}_surprisal',\n",
    "                        data=df_tmp_fold\n",
    "                    ).fit()\n",
    "\n",
    "                    results_comparison_df.append({\n",
    "                        \"y\": predicted_var, \n",
    "                        \"metric\": f\"Surprisal + IAS ({aggregation[1:]})\",\n",
    "                        \"model\": model, \n",
    "                        \"aggregation\": aggregation,\n",
    "                        \"dist_metric\": dist_metric,\n",
    "                        \"fold\": fold, \n",
    "                        \"loglik\": OLS_ias_surprisal.llf / OLS_ias_surprisal.nobs,\n",
    "                        \"delta_loglik\": OLS_ias_surprisal.llf / OLS_ias_surprisal.nobs - OLS_baseline.llf / OLS_baseline.nobs,\n",
    "                        \"rsquared\": OLS_ias_surprisal.rsquared,\n",
    "                        \"delta_rsquared\": OLS_ias_surprisal.rsquared - OLS_baseline.rsquared,\n",
    "                        \"rsquared_adj\": OLS_ias_surprisal.rsquared_adj,\n",
    "                        \"delta_rsquared_adj\": OLS_ias_surprisal.rsquared_adj - OLS_baseline.rsquared_adj,\n",
    "                        \"aic\": OLS_ias_surprisal.aic,\n",
    "                        \"bic\": OLS_ias_surprisal.bic,\n",
    "                        \"anova_p_vs_baseline\": \"\",\n",
    "                        \"anova_p_ias_vs_surprisal\": \"\",\n",
    "                        \"anova_p_surprisal_vs_ias\": \"\",\n",
    "                        \"anova_p_both_vs_ias\": \"\",\n",
    "                        \"anova_p_both_vs_surprisal\": \"\",\n",
    "                    })\n",
    "\n",
    "\n",
    "\n",
    "results_comparison_df = pd.DataFrame(results_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39bcd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_comparison_df.to_csv(\n",
    "    \"results_final/ols_aligned_ias_cosine_std_comparison_all.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6345e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
