{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:17:54.753035Z",
     "start_time": "2024-03-13T14:17:54.358878Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from string import punctuation\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad5e104b46ee1a",
   "metadata": {},
   "source": [
    "### Load Natural Stories reading times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b825310a6df7e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:17:55.300963Z",
     "start_time": "2024-03-13T14:17:54.753170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <th>correct</th>\n",
       "      <th>item</th>\n",
       "      <th>zone</th>\n",
       "      <th>RT</th>\n",
       "      <th>word</th>\n",
       "      <th>nItem</th>\n",
       "      <th>meanItemRT</th>\n",
       "      <th>sdItemRT</th>\n",
       "      <th>gmeanItemRT</th>\n",
       "      <th>gsdItemRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3QJPB0NZU5PY1</td>\n",
       "      <td>3960</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>160.579935</td>\n",
       "      <td>340.566023</td>\n",
       "      <td>1.490513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2RPQGUWVZPX7U</td>\n",
       "      <td>2431</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>474</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>160.579935</td>\n",
       "      <td>340.566023</td>\n",
       "      <td>1.490513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11KMPAZSE5Q0Q</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>160.579935</td>\n",
       "      <td>340.566023</td>\n",
       "      <td>1.490513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1U1QL617G5DU3</td>\n",
       "      <td>2074</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>160.579935</td>\n",
       "      <td>340.566023</td>\n",
       "      <td>1.490513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTW5YEWV9OR0</td>\n",
       "      <td>2213</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>160.579935</td>\n",
       "      <td>340.566023</td>\n",
       "      <td>1.490513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WorkerId  WorkTimeInSeconds  correct  item  zone   RT word  nItem  \\\n",
       "0  A3QJPB0NZU5PY1               3960        6     1     1  924   If     84   \n",
       "1  A2RPQGUWVZPX7U               2431        5     1     1  474   If     84   \n",
       "2  A11KMPAZSE5Q0Q               1287        5     1     1  272   If     84   \n",
       "3  A1U1QL617G5DU3               2074        6     1     1  354   If     84   \n",
       "4   ACTW5YEWV9OR0               2213        6     1     1  577   If     84   \n",
       "\n",
       "   meanItemRT    sdItemRT  gmeanItemRT  gsdItemRT  \n",
       "0  369.011905  160.579935   340.566023   1.490513  \n",
       "1  369.011905  160.579935   340.566023   1.490513  \n",
       "2  369.011905  160.579935   340.566023   1.490513  \n",
       "3  369.011905  160.579935   340.566023   1.490513  \n",
       "4  369.011905  160.579935   340.566023   1.490513  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_df = pd.read_csv('../data/corpora/naturalstories/processed_RTs.tsv', sep='\\t')\n",
    "ns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a74b44fa1ceb9a",
   "metadata": {},
   "source": [
    "### Load estimates of surprisal and incremental information value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef2bee7b665d3b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:17:55.301162Z",
     "start_time": "2024-03-13T14:17:55.221493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL_NAMES = ['gpt2-small', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'] \n",
    "\n",
    "FORECAST_HORIZONS = list(range(1, 11))\n",
    "\n",
    "LAYERS = {\n",
    "    \"gpt2-small\": list(range(0, 13)),\n",
    "    \"gpt2-medium\": list(range(0, 25, 2)),\n",
    "    \"gpt2-large\": list(range(0, 37, 3)),\n",
    "    \"gpt2-xl\": list(range(0, 49, 4))\n",
    "}\n",
    "\n",
    "SUMMARY_FNS = ['mean', 'max', 'min']\n",
    "\n",
    "UNIT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dd37b0e99f3ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:17:55.301397Z",
     "start_time": "2024-03-13T14:17:55.224846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>surprisal</th>\n",
       "      <th>tokens</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[5.37758064e+00 5.60565889e-01 3.75532675e+00 ...</td>\n",
       "      <td>['If' 'you' 'were' 'to' 'journey' 'to' 'the' '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[3.94234681e+00 8.24601555e+00 2.85127807e+00 ...</td>\n",
       "      <td>['A' 'clear' 'and' 'joyous' 'day' 'it' 'was' '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[4.69777489e+00 2.15857363e+00 7.92688084e+00 ...</td>\n",
       "      <td>['It' 'was' 'cold' 'and' 'nearly' 'dark' 'on' ...</td>\n",
       "      <td>gpt2-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[7.58915520e+00 2.35619020e+00 1.54661678e-03 ...</td>\n",
       "      <td>['Once' 'upon' 'a' 'time' 'the' 'birds' 'took'...</td>\n",
       "      <td>gpt2-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[6.06746483e+00 8.77776718e+00 1.15439475e+00 ...</td>\n",
       "      <td>['At' 'ten' 'years' 'old,' 'I' 'could' 'not' '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          surprisal  \\\n",
       "0   1  [5.37758064e+00 5.60565889e-01 3.75532675e+00 ...   \n",
       "1   2  [3.94234681e+00 8.24601555e+00 2.85127807e+00 ...   \n",
       "2   3  [4.69777489e+00 2.15857363e+00 7.92688084e+00 ...   \n",
       "3   4  [7.58915520e+00 2.35619020e+00 1.54661678e-03 ...   \n",
       "4   5  [6.06746483e+00 8.77776718e+00 1.15439475e+00 ...   \n",
       "\n",
       "                                              tokens       model  \n",
       "0  ['If' 'you' 'were' 'to' 'journey' 'to' 'the' '...  gpt2-small  \n",
       "1  ['A' 'clear' 'and' 'joyous' 'day' 'it' 'was' '...  gpt2-small  \n",
       "2  ['It' 'was' 'cold' 'and' 'nearly' 'dark' 'on' ...  gpt2-small  \n",
       "3  ['Once' 'upon' 'a' 'time' 'the' 'birds' 'took'...  gpt2-small  \n",
       "4  ['At' 'ten' 'years' 'old,' 'I' 'could' 'not' '...  gpt2-small  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surprisal\n",
    "\n",
    "ns_surprisal_path = \"../data/estimates/naturalstories/surprisal\"\n",
    "ns_surprisal_df = pd.DataFrame()\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    tmp_df = pd.read_csv(f'{ns_surprisal_path}/{model_name}_surprisal_400words.csv')\n",
    "    tmp_df['model'] = model_name\n",
    "    ns_surprisal_df = pd.concat([ns_surprisal_df, tmp_df], axis=0)\n",
    "\n",
    "# drop the entropy and deviation columns\n",
    "ns_surprisal_df = ns_surprisal_df.drop(columns=['entropy', 'deviation'])\n",
    "\n",
    "print(len(ns_surprisal_df), \"rows\")\n",
    "ns_surprisal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752433a606798bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:17:56.217811Z",
     "start_time": "2024-03-13T14:17:55.242897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>horizon</th>\n",
       "      <th>layer</th>\n",
       "      <th>summary</th>\n",
       "      <th>score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>model</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>[2.900254487991333, 0.9754052758216858, 2.7851...</td>\n",
       "      <td>['If', 'you', 'were', 'to', 'journey', 'to', '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>[2.7230708599090576, 3.9138975143432617, 2.982...</td>\n",
       "      <td>['A', 'clear', 'and', 'joyous', 'day', 'it', '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>[2.6567976474761963, 2.16483736038208, 3.67803...</td>\n",
       "      <td>['It', 'was', 'cold', 'and', 'nearly', 'dark',...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>[3.459038257598877, 3.1826250553131104, 0.0039...</td>\n",
       "      <td>['Once', 'upon', 'a', 'time', 'the', 'birds', ...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>[2.9816982746124268, 3.4702093601226807, 2.442...</td>\n",
       "      <td>['At', 'ten', 'years', 'old,', 'I', 'could', '...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  horizon  layer summary  \\\n",
       "0   1        1      0    mean   \n",
       "1   2        1      0    mean   \n",
       "2   3        1      0    mean   \n",
       "3   4        1      0    mean   \n",
       "4   5        1      0    mean   \n",
       "\n",
       "                                               score  \\\n",
       "0  [2.900254487991333, 0.9754052758216858, 2.7851...   \n",
       "1  [2.7230708599090576, 3.9138975143432617, 2.982...   \n",
       "2  [2.6567976474761963, 2.16483736038208, 3.67803...   \n",
       "3  [3.459038257598877, 3.1826250553131104, 0.0039...   \n",
       "4  [2.9816982746124268, 3.4702093601226807, 2.442...   \n",
       "\n",
       "                                              tokens       model  n  \n",
       "0  ['If', 'you', 'were', 'to', 'journey', 'to', '...  gpt2-small  1  \n",
       "1  ['A', 'clear', 'and', 'joyous', 'day', 'it', '...  gpt2-small  1  \n",
       "2  ['It', 'was', 'cold', 'and', 'nearly', 'dark',...  gpt2-small  1  \n",
       "3  ['Once', 'upon', 'a', 'time', 'the', 'birds', ...  gpt2-small  1  \n",
       "4  ['At', 'ten', 'years', 'old,', 'I', 'could', '...  gpt2-small  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incremental information value\n",
    "\n",
    "ns_iv_path = \"../data/estimates/naturalstories/iv_k50\"\n",
    "ns_iv_df = pd.DataFrame()\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    tmp_df = pd.read_csv(f'{ns_iv_path}/{model_name}_iv_n{UNIT_SIZE}_400words.csv')\n",
    "    tmp_df['model'] = model_name\n",
    "    tmp_df['n'] = UNIT_SIZE\n",
    "    ns_iv_df = pd.concat([ns_iv_df, tmp_df], axis=0)\n",
    "\n",
    "print(f\"{len(ns_iv_df)} rows.\")\n",
    "ns_iv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ce9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess score column\n",
    "\n",
    "def get_list(s):\n",
    "    \"\"\"\n",
    "    Transform \"score\" field (a string) into a list of floats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return literal_eval(s)\n",
    "    except SyntaxError:\n",
    "        return list(map(float, s[1:-1].split()))\n",
    "    except ValueError:\n",
    "        return list(map(float, s[1:-1].split()))\n",
    "    \n",
    "# transform \"scores\" in surprisal and incremental information value dataframes into lists of floats\n",
    "ns_iv_df['score'] = ns_iv_df['score'].apply(get_list)\n",
    "ns_surprisal_df['surprisal'] = ns_surprisal_df['surprisal'].apply(get_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1081700f23da8b2",
   "metadata": {},
   "source": [
    "### Annotate data points in Natural Stories with surprisal and information value estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85439eaa6f0dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:20:35.480793Z",
     "start_time": "2024-03-13T14:18:04.588053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract estimates...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec286041fd34b799ee677511377845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-arrange estimates for dataframe...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa3f87d7aa146389a3b6c9136d8ee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add estimates to main dataframe...\n"
     ]
    }
   ],
   "source": [
    "# Skip items with context lengths larger than 400 \n",
    "# (no estimates obtained for these; context too large for LM's context window)\n",
    "ns_df = ns_df[ns_df['zone'] <= 400]\n",
    "\n",
    "\n",
    "estimates = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "print('Extract estimates...')\n",
    "df_grouped = ns_df.groupby(['item', 'zone'])\n",
    "for (item, zone), group in tqdm(df_grouped, total=len(df_grouped)):\n",
    "    for model_name in MODEL_NAMES:\n",
    "        df_tmp = ns_surprisal_df[\n",
    "            (ns_surprisal_df['id'] == item) & \n",
    "            (ns_surprisal_df['model'] == model_name)\n",
    "        ]\n",
    "        estimates[f'{model_name}_surprisal'][(item, zone)] = df_tmp['surprisal'].values[0][zone - 1]\n",
    "\n",
    "    tmp_df_grouped = ns_iv_df[ns_iv_df[\"id\"] == item].groupby(\n",
    "        ['model', 'n', 'horizon', 'layer', 'summary']\n",
    "    )\n",
    "    for (model, n, horizon, layer, summary), group in tmp_df_grouped:\n",
    "        col = f'{model}_iv_{n}_H{horizon}_L{layer}_S{summary}'\n",
    "        estimates[col][(item, zone)] = group['score'].values[0][zone - 1]\n",
    "\n",
    "print('Re-arrange estimates for dataframe...')\n",
    "items_zones = list(zip(ns_df['item'].values, ns_df['zone'].values))\n",
    "estimates_rearranged = {}\n",
    "for k, v in tqdm(estimates.items(), total=len(estimates)):\n",
    "    estimates_rearranged[k] = [v[(item, zone)] for item, zone in items_zones]\n",
    "\n",
    "print('Add estimates to main dataframe...')\n",
    "ns_df = pd.concat(\n",
    "    [\n",
    "        ns_df,\n",
    "        pd.DataFrame(estimates_rearranged, index=ns_df.index)\n",
    "    ], axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85dbf2f9c9920d2",
   "metadata": {},
   "source": [
    "### Add control predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfc68d411a81fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:20:42.260108Z",
     "start_time": "2024-03-13T14:20:35.491402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <th>correct</th>\n",
       "      <th>item</th>\n",
       "      <th>zone</th>\n",
       "      <th>length</th>\n",
       "      <th>RT</th>\n",
       "      <th>word</th>\n",
       "      <th>nItem</th>\n",
       "      <th>meanItemRT</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L36_Smin</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L40_Smax</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L40_Smean</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L40_Smin</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L44_Smax</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L44_Smean</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L44_Smin</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L48_Smax</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L48_Smean</th>\n",
       "      <th>gpt2-xl_iv_1_H10_L48_Smin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3QJPB0NZU5PY1</td>\n",
       "      <td>3960</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>924</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>94.727402</td>\n",
       "      <td>560.528442</td>\n",
       "      <td>218.050339</td>\n",
       "      <td>113.002907</td>\n",
       "      <td>836.843384</td>\n",
       "      <td>285.529846</td>\n",
       "      <td>130.084595</td>\n",
       "      <td>29.212479</td>\n",
       "      <td>19.739662</td>\n",
       "      <td>10.837491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2RPQGUWVZPX7U</td>\n",
       "      <td>2431</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>474</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>94.727402</td>\n",
       "      <td>560.528442</td>\n",
       "      <td>218.050339</td>\n",
       "      <td>113.002907</td>\n",
       "      <td>836.843384</td>\n",
       "      <td>285.529846</td>\n",
       "      <td>130.084595</td>\n",
       "      <td>29.212479</td>\n",
       "      <td>19.739662</td>\n",
       "      <td>10.837491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11KMPAZSE5Q0Q</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>272</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>94.727402</td>\n",
       "      <td>560.528442</td>\n",
       "      <td>218.050339</td>\n",
       "      <td>113.002907</td>\n",
       "      <td>836.843384</td>\n",
       "      <td>285.529846</td>\n",
       "      <td>130.084595</td>\n",
       "      <td>29.212479</td>\n",
       "      <td>19.739662</td>\n",
       "      <td>10.837491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1U1QL617G5DU3</td>\n",
       "      <td>2074</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>94.727402</td>\n",
       "      <td>560.528442</td>\n",
       "      <td>218.050339</td>\n",
       "      <td>113.002907</td>\n",
       "      <td>836.843384</td>\n",
       "      <td>285.529846</td>\n",
       "      <td>130.084595</td>\n",
       "      <td>29.212479</td>\n",
       "      <td>19.739662</td>\n",
       "      <td>10.837491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTW5YEWV9OR0</td>\n",
       "      <td>2213</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>577</td>\n",
       "      <td>If</td>\n",
       "      <td>84</td>\n",
       "      <td>369.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>94.727402</td>\n",
       "      <td>560.528442</td>\n",
       "      <td>218.050339</td>\n",
       "      <td>113.002907</td>\n",
       "      <td>836.843384</td>\n",
       "      <td>285.529846</td>\n",
       "      <td>130.084595</td>\n",
       "      <td>29.212479</td>\n",
       "      <td>19.739662</td>\n",
       "      <td>10.837491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WorkerId  WorkTimeInSeconds  correct  item  zone  length   RT word  \\\n",
       "0  A3QJPB0NZU5PY1               3960        6     1     1       2  924   If   \n",
       "1  A2RPQGUWVZPX7U               2431        5     1     1       2  474   If   \n",
       "2  A11KMPAZSE5Q0Q               1287        5     1     1       2  272   If   \n",
       "3  A1U1QL617G5DU3               2074        6     1     1       2  354   If   \n",
       "4   ACTW5YEWV9OR0               2213        6     1     1       2  577   If   \n",
       "\n",
       "   nItem  meanItemRT  ...  gpt2-xl_iv_1_H10_L36_Smin  \\\n",
       "0     84  369.011905  ...                  94.727402   \n",
       "1     84  369.011905  ...                  94.727402   \n",
       "2     84  369.011905  ...                  94.727402   \n",
       "3     84  369.011905  ...                  94.727402   \n",
       "4     84  369.011905  ...                  94.727402   \n",
       "\n",
       "   gpt2-xl_iv_1_H10_L40_Smax  gpt2-xl_iv_1_H10_L40_Smean  \\\n",
       "0                 560.528442                  218.050339   \n",
       "1                 560.528442                  218.050339   \n",
       "2                 560.528442                  218.050339   \n",
       "3                 560.528442                  218.050339   \n",
       "4                 560.528442                  218.050339   \n",
       "\n",
       "   gpt2-xl_iv_1_H10_L40_Smin  gpt2-xl_iv_1_H10_L44_Smax  \\\n",
       "0                 113.002907                 836.843384   \n",
       "1                 113.002907                 836.843384   \n",
       "2                 113.002907                 836.843384   \n",
       "3                 113.002907                 836.843384   \n",
       "4                 113.002907                 836.843384   \n",
       "\n",
       "   gpt2-xl_iv_1_H10_L44_Smean  gpt2-xl_iv_1_H10_L44_Smin  \\\n",
       "0                  285.529846                 130.084595   \n",
       "1                  285.529846                 130.084595   \n",
       "2                  285.529846                 130.084595   \n",
       "3                  285.529846                 130.084595   \n",
       "4                  285.529846                 130.084595   \n",
       "\n",
       "   gpt2-xl_iv_1_H10_L48_Smax  gpt2-xl_iv_1_H10_L48_Smean  \\\n",
       "0                  29.212479                   19.739662   \n",
       "1                  29.212479                   19.739662   \n",
       "2                  29.212479                   19.739662   \n",
       "3                  29.212479                   19.739662   \n",
       "4                  29.212479                   19.739662   \n",
       "\n",
       "   gpt2-xl_iv_1_H10_L48_Smin  \n",
       "0                  10.837491  \n",
       "1                  10.837491  \n",
       "2                  10.837491  \n",
       "3                  10.837491  \n",
       "4                  10.837491  \n",
       "\n",
       "[5 rows x 1577 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word length (number of characters)\n",
    "ns_df['length'] = ns_df['word'].apply(len)\n",
    "\n",
    "# Re-arange columns\n",
    "cols = list(ns_df.columns)\n",
    "cols = cols[:5] + [cols[-1]] + cols[5:-1]\n",
    "ns_df = ns_df[cols]\n",
    "ns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ee7fd146936ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:21:14.065366Z",
     "start_time": "2024-03-13T14:20:42.271653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Bradford, not found in SUBTLEX\n",
      "Word clattered not found in SUBTLEX\n",
      "Word long-bearded not found in SUBTLEX\n",
      "Word boar's not found in SUBTLEX\n",
      "Word Bradford. not found in SUBTLEX\n",
      "Word Bradford not found in SUBTLEX\n",
      "Word beast's not found in SUBTLEX\n",
      "Word mother's not found in SUBTLEX\n",
      "Word marshmallow-like not found in SUBTLEX\n",
      "Word Aqua's not found in SUBTLEX\n",
      "Word gelid not found in SUBTLEX\n",
      "Word It's not found in SUBTLEX\n",
      "Word Year's, not found in SUBTLEX\n",
      "Word o'clock not found in SUBTLEX\n",
      "Word Correthers, not found in SUBTLEX\n",
      "Word Elvis's not found in SUBTLEX\n",
      "Word x-ray not found in SUBTLEX\n",
      "Word Abby's not found in SUBTLEX\n",
      "Word 'He's not found in SUBTLEX\n",
      "Word he's not found in SUBTLEX\n",
      "Word didn't not found in SUBTLEX\n",
      "Word wouldn't not found in SUBTLEX\n",
      "Word 'Where's not found in SUBTLEX\n",
      "Word Josephs not found in SUBTLEX\n",
      "Word dejectedly, not found in SUBTLEX\n",
      "Word 'I'm not found in SUBTLEX\n",
      "Word 'Haven't not found in SUBTLEX\n",
      "Word Lucy's not found in SUBTLEX\n",
      "Word mom's not found in SUBTLEX\n",
      "Word it's not found in SUBTLEX\n",
      "Word Roswell not found in SUBTLEX\n",
      "Word extra-terrestrial not found in SUBTLEX\n",
      "Word Roswell, not found in SUBTLEX\n",
      "Word forty-seven. not found in SUBTLEX\n",
      "Word high-altitude not found in SUBTLEX\n",
      "Word cover-up. not found in SUBTLEX\n",
      "Word forty-seven, not found in SUBTLEX\n",
      "Word field's not found in SUBTLEX\n",
      "Word seventy-eight, not found in SUBTLEX\n",
      "Word Stanton not found in SUBTLEX\n",
      "Word cover-up not found in SUBTLEX\n",
      "Word made-for-TV not found in SUBTLEX\n",
      "Word thirty-seven, not found in SUBTLEX\n",
      "Word ninety-three, not found in SUBTLEX\n",
      "Word l'Ecluse not found in SUBTLEX\n",
      "Word Leiden not found in SUBTLEX\n",
      "Word Emperor's not found in SUBTLEX\n",
      "Word one-colored not found in SUBTLEX\n",
      "Word Couleren, not found in SUBTLEX\n",
      "Word Rosen not found in SUBTLEX\n",
      "Word Violetten not found in SUBTLEX\n",
      "Word Bizarden not found in SUBTLEX\n",
      "Word sought-after not found in SUBTLEX\n",
      "Word tulip-specific not found in SUBTLEX\n",
      "Word prefixed not found in SUBTLEX\n",
      "Word seven-twelve not found in SUBTLEX\n",
      "Word Tourette's not found in SUBTLEX\n",
      "Word Georges not found in SUBTLEX\n",
      "Word Gilles not found in SUBTLEX\n",
      "Word eighty-six-year-old not found in SUBTLEX\n",
      "Word Tourette's, not found in SUBTLEX\n",
      "Word self-diagnosed not found in SUBTLEX\n",
      "Word throat-clearing, not found in SUBTLEX\n",
      "Word self-harm not found in SUBTLEX\n"
     ]
    }
   ],
   "source": [
    "# Subtlex log frequency\n",
    "subtlex_df = pd.read_excel('../data/SUBTLEXusExcel2007.xlsx')\n",
    "subtlex = {}\n",
    "for index, row in subtlex_df.iterrows():\n",
    "    subtlex[row['Word']] = row['Lg10WF']\n",
    "\n",
    "# Natural Stories vocabulary\n",
    "vocab = ns_df['word'].unique()\n",
    "\n",
    "# Add frequency information to the dataframe\n",
    "for word in vocab:\n",
    "    if word in subtlex: \n",
    "        freq = subtlex[word]\n",
    "    elif word.lower() in subtlex:\n",
    "        freq = subtlex[word.lower()]\n",
    "    elif word.capitalize() in subtlex:\n",
    "        freq = subtlex[word.capitalize()]\n",
    "    else:\n",
    "        _word = word.strip(punctuation)\n",
    "        if _word in subtlex:\n",
    "            freq = subtlex[_word]\n",
    "        elif _word.lower() in subtlex:\n",
    "            freq = subtlex[_word.lower()]\n",
    "        elif _word.capitalize() in subtlex:\n",
    "            freq = subtlex[_word.capitalize()]\n",
    "        else:\n",
    "            print(f\"Word {word} not found in SUBTLEX\")\n",
    "            freq = np.nan\n",
    "    # Add log frequency to the dataframe\n",
    "    ns_df.loc[ns_df['word'] == word, 'Subtlex_log10'] = freq\n",
    "    \n",
    "# Re-arrange columns\n",
    "cols = list(ns_df.columns)\n",
    "cols = cols[:6] + [cols[-1]] + cols[6:-1]\n",
    "ns_df = ns_df[cols]\n",
    "\n",
    "# Drop rows for which Subtlex log frequency is not available\n",
    "ns_df_clean = ns_df.copy()\n",
    "ns_df_clean = ns_df_clean.dropna(subset=['Subtlex_log10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d111c2b3882a5",
   "metadata": {},
   "source": [
    "### Further preprocessing following De Varda et al. 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2d5ada04dd6618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:29:14.682031Z",
     "start_time": "2024-03-13T14:27:48.071271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Punctuation\n",
    "# From Frank: \"Words attached to a comma, clitics, sentence-initial, and sentence-final words \n",
    "#              were discarded from further analysis [...].\"\n",
    "def contains_punct(word):\n",
    "    if \".\" in word:\n",
    "        return 1\n",
    "    elif \",\" in word:\n",
    "        return 1\n",
    "    elif \"'\" in word:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ns_df_clean[\"contains_punct\"] = ns_df_clean[\"word\"].apply(contains_punct)\n",
    "ns_df_clean = ns_df_clean[ns_df_clean.contains_punct == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dae324b",
   "metadata": {},
   "source": [
    "### Create a normalised version of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa605050933307a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:49:45.680486Z",
     "start_time": "2024-03-13T14:49:45.657366Z"
    }
   },
   "outputs": [],
   "source": [
    "BASELINE_PREDICTORS = ['Subtlex_log10', 'length', 'zone']\n",
    "SURPRISAL_PREDICTORS = [col for col in ns_df_clean if '_surprisal' in col]\n",
    "IV_PREDICTORS = [col for col in ns_df_clean if '_iv_' in col]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ns_df_clean_norm = ns_df_clean.copy()\n",
    "ns_df_clean_norm[IV_PREDICTORS + SURPRISAL_PREDICTORS] = scaler.fit_transform(ns_df_clean_norm[IV_PREDICTORS + SURPRISAL_PREDICTORS])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43c942",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a562f728b41918d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T14:48:11.867876Z",
     "start_time": "2024-03-13T14:29:15.151727Z"
    }
   },
   "outputs": [],
   "source": [
    "# this can take a while... (runtime: 19m 56s)\n",
    "\n",
    "ns_df_clean.to_csv(\n",
    "    'preprocessed_corpora/naturalstories_preprocessed.csv', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "ns_df_clean_norm.to_csv(\n",
    "    'preprocessed_corpora/naturalstories_preprocessed_normalised.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44a1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
